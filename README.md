# ğŸ™ï¸ Wake-Sleep STT Module

A modular, event-driven **Speech-to-Text** system with **wake/sleep word detection**. Completely **free**, **offline**, and **reusable** for mobile (React Native) and desktop applications.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Node.js](https://img.shields.io/badge/node-%3E%3D14.0.0-brightgreen)](https://nodejs.org/)

---

## âœ¨ Features

- ğŸ¤ **Real-time speech-to-text transcription**
- ğŸ”“ **100% Free & Offline** (uses Vosk - no API keys required)
- ğŸ‘‚ **Wake word activation** (e.g., say "Hi" to start)
- ğŸ’¤ **Sleep word deactivation** (e.g., say "Bye" to stop)
- ğŸ”„ **Repeatable cycle** (wake â†’ transcribe â†’ sleep â†’ repeat)
- ğŸ“± **React Native compatible** design
- ğŸ¯ **Event-driven architecture** for easy integration
- âš™ï¸ **Highly customizable** (wake/sleep words, sample rate, etc.)

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js v14.0.0 or higher
- Working microphone
- ~50MB disk space for Vosk model

### Installation

1. **Clone or download this module**
   ```bash
   cd wake-sleep-stt-module
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Download Vosk model**
   - Visit: https://alphacephei.com/vosk/models
   - Download: `vosk-model-small-en-us-0.15.zip` (40MB)
   - Extract to: `wake-sleep-stt-module/models/`

   Your folder structure should look like:
   ```
   wake-sleep-stt-module/
   â””â”€â”€ models/
       â””â”€â”€ vosk-model-small-en-us-0.15/
           â”œâ”€â”€ am/
           â”œâ”€â”€ conf/
           â”œâ”€â”€ graph/
           â””â”€â”€ ...
   ```

4. **Run the demo**
   ```bash
   npm run demo
   ```

5. **Test it out!**
   - Say **"Hi"** to activate transcription
   - Speak anything - see real-time transcription
   - Say **"Bye"** to stop transcription
   - Repeat the cycle as needed!

---

## ğŸ“– Usage

### Basic Example

```javascript
import WakeSleepSTT from './src/WakeSleepSTT.js';

// Create instance
const stt = new WakeSleepSTT({
  wakeWord: 'hi',
  sleepWord: 'bye',
  modelPath: './models/vosk-model-small-en-us-0.15',
  debug: true
});

// Listen to events
stt.on('wakeWordDetected', () => {
  console.log('ğŸ¤ Wake word detected! Start speaking...');
});

stt.on('transcription', (data) => {
  console.log('ğŸ“ Transcription:', data.text);
});

stt.on('sleepWordDetected', () => {
  console.log('ğŸ’¤ Sleep word detected! Pausing...');
});

// Initialize and start
await stt.initialize();
stt.start();
```

### Custom Wake/Sleep Words

```javascript
const stt = new WakeSleepSTT({
  wakeWord: 'jarvis',     // Custom wake word
  sleepWord: 'sleep',     // Custom sleep word
  modelPath: './models/vosk-model-small-en-us-0.15'
});
```

---

## ğŸª Events

The module emits the following events:

| Event | Description |
|-------|-------------|
| `initialized` | Model loaded successfully |
| `started` | Microphone started |
| `listeningForWakeWord` | Waiting for wake word |
| `wakeWordDetected` | Wake word spoken |
| `transcriptionStarted` | Transcription activated |
| `partialTranscription` | Real-time partial results |
| `transcription` | Final transcription result |
| `sleepWordDetected` | Sleep word spoken |
| `transcriptionStopped` | Transcription deactivated |
| `stopped` | System stopped |
| `error` | Error occurred |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Wake-Sleep STT Module (Core)             â”‚
â”‚  - WakeSleepSTT.js (Main class)              â”‚
â”‚  - Event-driven architecture                  â”‚
â”‚  - State management                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚  Vosk  â”‚    â”‚   Mic   â”‚
â”‚ (STT)  â”‚    â”‚ (Audio) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**State Flow:**
```
Listening for Wake Word â†’ Wake Word Detected â†’
Transcription Active â†’ Sleep Word Detected â†’
(Loop back to Listening for Wake Word)
```

---

## ğŸ“± React Native Integration

This module is designed to be reusable in React Native apps. You'll need to create a native bridge to access the microphone and Vosk library on mobile.

**Example React Native Component:**

```javascript
import React, { useEffect, useState } from 'react';
import { View, Text, Button } from 'react-native';
import WakeSleepSTTNative from './WakeSleepSTTNative';

const TranscriptionScreen = () => {
  const [transcription, setTranscription] = useState('');
  const [isActive, setIsActive] = useState(false);

  const stt = new WakeSleepSTTNative({
    wakeWord: 'hi',
    sleepWord: 'bye',
  });

  useEffect(() => {
    stt.on('transcription', (data) => {
      setTranscription(data.text);
    });

    stt.on('wakeWordDetected', () => setIsActive(true));
    stt.on('sleepWordDetected', () => setIsActive(false));

    return () => stt.cleanup();
  }, []);

  return (
    <View>
      <Text>Status: {isActive ? 'Active ğŸ¤' : 'Waiting ğŸ‘‚'}</Text>
      <Text>Transcription: {transcription}</Text>
      <Button title="Start" onPress={() => stt.start()} />
    </View>
  );
};
```

See `DOCUMENTATION.md` for full React Native implementation details.

---

## ğŸ”§ Configuration Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `wakeWord` | string | 'hi' | Word to activate transcription |
| `sleepWord` | string | 'bye' | Word to deactivate transcription |
| `modelPath` | string | null | Path to Vosk model (required) |
| `sampleRate` | number | 16000 | Audio sample rate (Hz) |
| `channels` | number | 1 | Audio channels (1=mono) |
| `debug` | boolean | false | Enable debug logging |

---

## ğŸ› ï¸ Platform-Specific Setup

### Windows
```bash
# If 'mic' module fails to install
npm install --global windows-build-tools
```

### macOS
```bash
# Install audio processing tools
brew install sox
```

### Linux
```bash
# Install ALSA and SoX
sudo apt-get install libasound2-dev sox libsox-fmt-all
```

---

## ğŸ“š API Reference

### Methods

#### `async initialize()`
Load Vosk model and prepare recognizer.
```javascript
await stt.initialize();
```

#### `start()`
Start microphone and begin listening for wake word.
```javascript
stt.start();
```

#### `stop()`
Stop microphone and recognition.
```javascript
stt.stop();
```

#### `cleanup()`
Free all resources (model, recognizer, microphone).
```javascript
stt.cleanup();
```

#### `getState()`
Get current state of the module.
```javascript
const state = stt.getState();
// Returns: { isListeningForWakeWord, isTranscribing, wakeWord, sleepWord }
```

---

## ğŸ§ª Testing

Run the demo on your PC/laptop:
```bash
npm run demo
```

**Expected behavior:**
1. Say "Hi" â†’ Transcription starts
2. Speak anything â†’ See real-time transcription
3. Say "Bye" â†’ Transcription stops
4. Repeat cycle as needed

---

## ğŸ› Troubleshooting

### Model not found?
Download from https://alphacephei.com/vosk/models and extract to `models/` folder.

### Microphone not working?
- Check microphone permissions (Settings â†’ Privacy â†’ Microphone)
- Test microphone with other apps
- Try different microphone device

### Wake word not detecting?
- Speak clearly and close to microphone
- Reduce background noise
- Try different wake word
- Enable debug logging: `debug: true`

### Low accuracy?
- Use larger model (`vosk-model-en-us-0.22` instead of small model)
- Improve microphone quality
- Adjust sample rate

See `DOCUMENTATION.md` for detailed troubleshooting.

---

## ğŸ“‚ Project Structure

```
wake-sleep-stt-module/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ WakeSleepSTT.js      # Core module (main class)
â”‚   â””â”€â”€ index.js             # Entry point
â”œâ”€â”€ demo/
â”‚   â””â”€â”€ demo.js              # PC/Laptop demo script
â”œâ”€â”€ models/
â”‚   â””â”€â”€ [Download Vosk model here]
â”œâ”€â”€ package.json             # Dependencies & scripts
â”œâ”€â”€ README.md                # This file
â””â”€â”€ DOCUMENTATION.md         # Technical documentation
```

---

## ğŸ¯ Use Cases

- **Voice assistants**: "Alexa", "Hey Siri" style activation
- **Hands-free apps**: Medical, industrial, accessibility apps
- **Meeting transcription**: Activate when meeting starts
- **Voice notes**: Quick voice-to-text for note-taking
- **IoT devices**: Voice-controlled smart home devices

---

## ğŸŒŸ Why This Module?

| Feature | This Module | Cloud APIs | Other Solutions |
|---------|-------------|------------|-----------------|
| **Cost** | âœ… Free | âŒ Paid | âš ï¸ Varies |
| **Offline** | âœ… Yes | âŒ No | âš ï¸ Some |
| **Privacy** | âœ… 100% local | âŒ Cloud | âš ï¸ Varies |
| **Wake/Sleep Words** | âœ… Built-in | âŒ Manual | âŒ Manual |
| **Real-time** | âœ… Yes | âœ… Yes | âš ï¸ Varies |
| **React Native Ready** | âœ… Yes | âš ï¸ SDK needed | âŒ Limited |

---

## ğŸ“„ License

MIT License - Free for personal and commercial use.

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Multi-word wake phrases
- Confidence scoring
- Multiple language support
- React Native native modules
- Performance optimizations

---

## ğŸ“ Support

- **Documentation**: See `DOCUMENTATION.md` for detailed technical docs
- **Demo**: Run `npm run demo` for live example
- **Issues**: Check troubleshooting section above

---

## ğŸ¥ Demo Video

Create a 2-minute video showing:
1. Running `npm run demo`
2. Saying "Hi" to activate
3. Speaking and showing transcription
4. Saying "Bye" to deactivate
5. Brief code walkthrough (`WakeSleepSTT.js`)

---

**Built for hackathons, learning, and real-world applications ğŸš€**

â­ If you find this useful, please star the repository!
